# ===========================================
# AI Podcast Generator - Environment Variables
# ===========================================

# Project
PROJECT_NAME=AI Podcast Generator
DEBUG=false

# Database - Neon PostgreSQL (Free Tier)
# Get from: https://neon.tech
DATABASE_URL=postgresql://neondb_owner:npg_K4PJwc3WzpGD@ep-small-breeze-adf9631c-pooler.c-2.us-east-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require

# Redis - Upstash (Free Tier)
# Get from: https://upstash.com
REDIS_URL=redis://default:your-password@your-host.upstash.io:6379

# Qdrant Cloud (Free Tier)
# Get from: https://cloud.qdrant.io
QDRANT_URL=https://cdb3d145-60a0-4f1a-8fa9-1c7b3f01f866.europe-west3-0.gcp.cloud.qdrant.io
QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.IHKzzQRRz9leSWnAQOGcRBAxhK4cpkuaiD4HNs6P4MY

# HuggingFace (Free Inference API)
# Get from: https://huggingface.co/settings/tokens
HF_API_TOKEN=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

# LLM Model (via HuggingFace or Ollama)
HF_LLM_MODEL=meta-llama/Meta-Llama-3-8B-Instruct
HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Ollama (Local LLM - Alternative to HF)
# Install from: https://ollama.ai
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# TTS Model (Coqui XTTS)
TTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2

# Whisper STT Model
WHISPER_MODEL=base

# SDXL Image Generation
SDXL_MODEL=stabilityai/stable-diffusion-xl-base-1.0

# File Storage
UPLOAD_DIR=/tmp/podcast_uploads
OUTPUT_DIR=/tmp/podcast_outputs
MAX_UPLOAD_SIZE=52428800

# Worker Settings
WORKER_QUEUE=podcast_jobs
JOB_TIMEOUT=3600

# CORS (comma-separated origins)
CORS_ORIGINS=*
